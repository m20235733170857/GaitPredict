{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sys\n",
    "#from keras_tcn import TCN\n",
    "#import tensorflow_addons as tfa\n",
    "import typeguard\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"SciPy version: {scipy.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只預測右腳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 644\u001b[0m\n\u001b[1;32m    642\u001b[0m logger \u001b[38;5;241m=\u001b[39m setup_logging()\n\u001b[1;32m    643\u001b[0m processor \u001b[38;5;241m=\u001b[39m DataProcessor(logger)\n\u001b[0;32m--> 644\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 使用默認的 localhost:23456\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 602\u001b[0m, in \u001b[0;36mDataProcessor.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型已預熱\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# 1. 初始化 Unity 客戶端\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m#client_socket, send_signal = self.TCP_For_Unity(host='localhost', port=12345)\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# 2. 啟動 IMU 伺服器\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTCP_For_IMU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m34567\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m setup_logging()  \u001b[38;5;66;03m# 在程式啟動時呼叫\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# 創建並啟動線程\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 582\u001b[0m, in \u001b[0;36mDataProcessor.TCP_For_IMU\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m    579\u001b[0m server\u001b[38;5;241m.\u001b[39mlisten(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 允許 1 個連線\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m伺服器已啟動，等待連線...據\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 582\u001b[0m conn, addr \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m已連接來自 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 的客戶端\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn  \u001b[38;5;66;03m# 回傳 conn 以供後續使用\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Predict_HS_gpu/lib/python3.10/socket.py:293\u001b[0m, in \u001b[0;36msocket.accept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maccept\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"accept() -> (socket object, address info)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    Wait for an incoming connection.  Return a new socket\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    representing the connection, and the address of the client.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    For IP sockets, the address info is a pair (hostaddr, port).\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     fd, addr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accept\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     sock \u001b[38;5;241m=\u001b[39m socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfamily, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto, fileno\u001b[38;5;241m=\u001b[39mfd)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# Issue #7995: if no default timeout is set and the listening\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# socket had a (non-zero) timeout, force the new socket in blocking\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# mode to override platform-specific socket flags inheritance.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import register_keras_serializable  # 改用這個路徑\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, TimeDistributed \n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import socket\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import threading\n",
    "import queue\n",
    "from collections import deque\n",
    "import time\n",
    "import asyncio\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import nest_asyncio\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import numba\n",
    "import logging\n",
    "import psutil\n",
    "\n",
    "# 更專業的日誌配置\n",
    "def setup_logging():\n",
    "    \"\"\"設置日誌記錄系統\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s.%(msecs)03d | %(levelname)-8s | %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler('/home/ndt/Desktop/predict_model/comprehensive_log.log'),\n",
    "            logging.StreamHandler()  # 同時輸出到控制台\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "#預測函數\n",
    "def predict_data10step_graph(model_predict, data_min, data_max, feature_min, feature_max):\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 7], dtype=tf.float32)])\n",
    "    def predict_fn(imu_data_40step):\n",
    "        start_time = tf.timestamp()\n",
    "        \n",
    "        past_data = imu_data_40step[-40:, 5:6]\n",
    "        past_data_scaled = (past_data - data_min) / (data_max - data_min + 1e-8)\n",
    "        past_data_scaled = past_data_scaled * (feature_max - feature_min) + feature_min\n",
    "        past_data_scaled = tf.reshape(past_data_scaled, [1, 40, 1])\n",
    "        \n",
    "        decoder_input_test = tf.zeros([1, 10, 1], dtype=tf.float32)\n",
    "        predictions_ta = tf.TensorArray(dtype=tf.float32, size=10)\n",
    "        \n",
    "        def loop_body(step, decoder_input_test, predictions_ta):\n",
    "            prediction_step = model_predict([past_data_scaled, decoder_input_test])\n",
    "            new_prediction = prediction_step[0, 0, 0]\n",
    "            predictions_ta = predictions_ta.write(step, new_prediction)\n",
    "            if step < 9:\n",
    "                decoder_input_test = tf.tensor_scatter_nd_update(\n",
    "                    decoder_input_test, [[0, step + 1, 0]], [new_prediction]\n",
    "                )\n",
    "            return step + 1, decoder_input_test, predictions_ta\n",
    "        \n",
    "        # Use tf.while_loop with all state variables\n",
    "        step = tf.constant(0)\n",
    "        step, decoder_input_test, predictions_ta = tf.while_loop(\n",
    "            lambda step, _, __: step < 10,  # Condition only checks step\n",
    "            loop_body,\n",
    "            [step, decoder_input_test, predictions_ta]\n",
    "        )\n",
    "        \n",
    "        predictions_scaled = predictions_ta.stack()\n",
    "        predictions_orig = predictions_scaled * (data_max - data_min) / (feature_max - feature_min) + data_min\n",
    "        \n",
    "        future_data = tf.zeros([10, 7], dtype=tf.float32)\n",
    "        indices = tf.stack([tf.range(10), tf.fill([10], 5)], axis=1)\n",
    "        future_data = tf.tensor_scatter_nd_update(future_data, indices, predictions_orig)\n",
    "        \n",
    "        full_data = tf.concat([imu_data_40step[-40:, :], future_data], axis=0)\n",
    "        \n",
    "        end_time = tf.timestamp()\n",
    "        exec_time = end_time - start_time\n",
    "        #tf.print(f\"predict_data10step execution time: {exec_time} seconds\")\n",
    "        return full_data\n",
    "    return predict_fn\n",
    "\n",
    "def detectHS_graph(model_HS):\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 7], dtype=tf.float32)])\n",
    "    def detect_fn(imu_data_50step):\n",
    "        start_time = tf.timestamp()\n",
    "        # processed_data：直接使用 imu_data_50step（假设数据已完整）\n",
    "        processed_data = imu_data_50step[-50:, 1:7]\n",
    "\n",
    "        # 使用 TensorFlow 的標準化，模仿 sklearn 的行为\n",
    "        mean, variance = tf.nn.moments(processed_data, axes=[0])\n",
    "        input_scaled = (processed_data - mean) / tf.sqrt(variance + 1e-8)\n",
    "        input_scaled = tf.reshape(input_scaled, [1, 50, 6])\n",
    "        \n",
    "        # 使用GPU执行HS模型预测，直接调用模型\n",
    "        hs_level = model_HS(input_scaled)\n",
    "        \n",
    "        # 使用 tf.cond 替代 if 语句\n",
    "        cond1 = hs_level[0, 49, 0] > 0.015\n",
    "        cond2 = imu_data_50step[49, 5] * 180 / 3.14 < -10\n",
    "        signal = tf.cond(\n",
    "            tf.logical_and(cond1, cond2), \n",
    "            lambda: tf.constant(1, dtype=tf.int32), \n",
    "            lambda: tf.constant(0, dtype=tf.int32)\n",
    "        )\n",
    "        \n",
    "        end_time = tf.timestamp()\n",
    "        exec_time = end_time - start_time\n",
    "        #tf.print(f\"{datetime.now()} detectHS execution time:\", exec_time, \"seconds\")\n",
    "        return signal\n",
    "    return detect_fn\n",
    "\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=[10000, 7], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "])\n",
    "def combined_predict_and_detect(data_5610_tensor, data_count, data_index):\n",
    "    total_start = tf.timestamp()\n",
    "\n",
    "    # 始終使用 data_index 提取最近 40 筆數據\n",
    "    if data_index == 0:\n",
    "        current_data = data_5610_tensor[-40:, :]\n",
    "    else:\n",
    "        current_data = tf.concat(\n",
    "            [data_5610_tensor[data_index:], data_5610_tensor[:data_index]],\n",
    "            axis=0\n",
    "        )[-40:, :]\n",
    "\n",
    "    if data_count < 10000:\n",
    "        current_data = data_5610_tensor[:data_count][-40:, :]\n",
    "    else:\n",
    "        current_data = tf.concat(\n",
    "            [data_5610_tensor[data_index:], data_5610_tensor[:data_index]],\n",
    "            axis=0\n",
    "        )[-40:, :]\n",
    "        \n",
    "    start_time = tf.timestamp()\n",
    "    data_5610_50step = predict_data10step_R(current_data)\n",
    "    end_time = tf.timestamp()\n",
    "    tf.print(\"predict_data10step_R execution time:\", end_time - start_time, \"seconds\")\n",
    "\n",
    "    start_time = tf.timestamp()\n",
    "    signal = detectHS(data_5610_50step)\n",
    "    end_time = tf.timestamp()\n",
    "    tf.print(\"detectHS execution time:\", end_time - start_time, \"seconds\")\n",
    "\n",
    "    total_end = tf.timestamp()\n",
    "    tf.print(\"Total combined_predict_and_detect execution time:\", total_end - total_start, \"seconds\")\n",
    "    return signal\n",
    "\n",
    "# 重建原本detectHS的模型，因為這邊環境跟ndt_cpu不一樣\n",
    "model_HS = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(\n",
    "        units=64,\n",
    "        return_sequences=True,  # 必須設為 True 來保持序列長度\n",
    "        input_shape=(50, 6),    # 從原始配置中的 batch_input_shape\n",
    "        dropout=0.2,\n",
    "        recurrent_dropout=0.1,\n",
    "        name='lstm_2'           # 使用相同的層名稱\n",
    "    ),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='dense_2'\n",
    "    ),\n",
    "    tf.keras.layers.Activation(\n",
    "        'sigmoid',\n",
    "        name='activation_2'\n",
    "    )\n",
    "])\n",
    "\n",
    "# 編譯模型\n",
    "model_HS.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 打印模型摘要以驗證結構\n",
    "#model_HS.summary()\n",
    "\n",
    "# 嘗試載入權重\n",
    "try:\n",
    "    model_HS.load_weights(\"/home/ndt/Desktop/predict_model/model_weights.h5\")\n",
    "    detectHS = detectHS_graph(model_HS)\n",
    "    print(f\"{datetime.now()} 權重載入成功！\")\n",
    "except Exception as e:\n",
    "    print(\"載入權重時出錯：\", e)\n",
    "\n",
    "#以下是預測HS模型建置\n",
    "\n",
    "# 1. 首先定義相同的 PositionalEncoding 層\n",
    "@register_keras_serializable() # 使用 register_keras_serializable 直接註冊\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim, **kwargs):  # 添加 **kwargs 來接受額外的參數\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)  # 將 **kwargs 傳遞給父類\n",
    "        self.pos_emb = self.add_weight(name=\"pos_emb\",\n",
    "                                     shape=(1, maxlen, embed_dim))\n",
    "        # 保存參數供序列化使用\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_emb\n",
    "\n",
    "    # 加入這個方法以支援序列化\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"maxlen\": self.maxlen,\n",
    "            \"embed_dim\": self.embed_dim\n",
    "        })\n",
    "        return config\n",
    "custom_objects = {\"PositionalEncoding\": PositionalEncoding}\n",
    "#model_predictL = keras.models.load_model('/mnt/c/Users/m2023/Desktop/vision/predict_model/modelSeq2Seq LSTM with Positional Encoding and Multi-Head Attention For 1 Input For Left20250225.keras', custom_objects=custom_objects) #predict IMU for left\n",
    "model_predictR = keras.models.load_model('/home/ndt/Desktop/predict_model/modelSeq2Seq LSTM with Positional Encoding and Multi-Head Attention For 1 Input For Right20250225.keras', custom_objects=custom_objects) #predict IMU for right \n",
    "scaler_right = joblib.load('/home/ndt/Desktop/predict_model/right_scaler_20250225.pkl')\n",
    "scaler_left = joblib.load('/home/ndt/Desktop/predict_model/left_scaler_20250225.pkl')\n",
    "\n",
    "# 提取 scaler 參數\n",
    "data_min_right = float(scaler_right.data_min_[0])\n",
    "data_max_right = float(scaler_right.data_max_[0])\n",
    "feature_min_right = scaler_right.feature_range[0]\n",
    "feature_max_right = scaler_right.feature_range[1]\n",
    "\n",
    "\n",
    "#predict_data10step_L = predict_data10step_graph(model_predictL, scaler_left)\n",
    "# 定義預測函數\n",
    "predict_data10step_R = predict_data10step_graph(\n",
    "    model_predictR,\n",
    "    data_min_right,\n",
    "    data_max_right,\n",
    "    feature_min_right,\n",
    "    feature_max_right\n",
    ")\n",
    "\n",
    "\n",
    "#model_predictL.summary()\n",
    "\n",
    "\n",
    "# 初始化狀態機狀態\n",
    "state = \"IDLE\"  # 初始狀態\n",
    "step_counter = 0  # 用於記錄新增的步數\n",
    "start_index = 0\n",
    "predict_state = 1\n",
    "running = True  # 設置一個標誌來控制程式運行\n",
    "signal = 0\n",
    "\n",
    "\n",
    "cue_step = 5 #提前幾步cue\n",
    "TRIAL_NAME = '20250306-1HS'\n",
    "output_file = \"/mnt/c/Users/m2023/Desktop/experience_data/\"\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.data_queue = queue.Queue()\n",
    "        self.running_event = threading.Event()\n",
    "        self.running_event.set()\n",
    "        self.prediction_thread = None  # 新增預測執行緒控制\n",
    "        self.prediction_active = threading.Event()  # 控制預測執行緒的運行\n",
    "        \n",
    "        # 預測相關的變量\n",
    "        self.predict_state = None\n",
    "        self.state = \"IDLE\"\n",
    "        #self.data_5610 = np.array([[1,2,3,4,5,6,7]])\n",
    "        #self.data_5611 = np.array([[1,2,3,4,5,6,7]])\n",
    "        with tf.device('/GPU:0'):\n",
    "            self.data_5610_tensor = tf.Variable(np.zeros((10000, 7), dtype=np.float32))  # 初始為 1000x7 的零陣列\n",
    "            #self.latest_40_data = tf.Variable(np.zeros((40, 7), dtype=np.float32))\n",
    "        self.data_index = 0  # 下一個數據插入的位置\n",
    "        self.data_count = 0  # 已接收的數據總數，最大 1000\n",
    "\n",
    "        self.data_lock = threading.Lock()  # 只用於寫入保護\n",
    "\n",
    "        self.R_HeelStrike_Predict_Time=np.array([[1]])\n",
    "        self.L_HeelStrike_Predict_Time=np.array([[1]])\n",
    "\n",
    "        self.execution_overtime_count = 0\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # 創建進程池用於預測\n",
    "        #self.process_pool = ProcessPoolExecutor(max_workers=1)\n",
    "\n",
    "        # 修改進程池的創建方式，改為需要時才創建\n",
    "        self.process_pool = None\n",
    "\n",
    "    def _init_process_pool(self):\n",
    "        \"\"\"初始化或重新初始化進程池\"\"\"\n",
    "        if hasattr(self, 'process_pool'):\n",
    "            self.process_pool.shutdown(wait=False)\n",
    "        self.process_pool = ProcessPoolExecutor(max_workers=1)\n",
    "    \n",
    "    def receive_data(self, conn):\n",
    "        \"\"\"接收數據的線程函數\"\"\"\n",
    "        buffer = \"\"\n",
    "        while self.running_event.is_set():\n",
    "            try:\n",
    "                data = conn.recv(1024)  # 增加緩衝區大小\n",
    "                if not data:\n",
    "                    print(\"客戶端已斷開連接\")\n",
    "                    self.running_event.clear()\n",
    "                    break\n",
    "                # 將接收到的數據追加到緩衝區\n",
    "                buffer += data.decode()\n",
    "                # 分割完整的消息（考慮多個換行符的情況）\n",
    "                messages = buffer.split('\\n')\n",
    "                # 最後一個元素可能是不完整的消息，使用messages[-1]讀最後一個元素保留在buffer中\n",
    "                buffer = messages[-1]\n",
    "\n",
    "                # messages[:-1]是指除了除了最後一個元素以外的所有完整消息\n",
    "                for message in messages[:-1]: \n",
    "                    if message.strip():  # 確保消息不是空字符串\n",
    "                        self.data_queue.put(message.strip())\n",
    "                        #print(f\"已放入隊列：{message}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"接收數據時發生錯誤：{e}\")\n",
    "                self.running_event.clear()\n",
    "                break\n",
    "\n",
    "    def process_data(self):\n",
    "        \"\"\"處理數據的線程函數\"\"\"\n",
    "        batch_size = 1  # 批量處理大小\n",
    "        batch = []\n",
    "        \n",
    "        while self.running_event.is_set():\n",
    "            try:\n",
    "                # 批量收集數據\n",
    "                while len(batch) < batch_size:\n",
    "                    try:\n",
    "                        message = self.data_queue.get()\n",
    "                        batch.append(message)\n",
    "                        if self.data_queue.qsize() > 100:\n",
    "                            self.logger.info(f\"警告：佇列堆積，當前大小: {self.data_queue.qsize()}\")\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "\n",
    "                if not batch:\n",
    "                    #time.sleep(0.001)  # 短暫休眠避免CPU空轉\n",
    "                    continue\n",
    "\n",
    "                # 批量處理數據\n",
    "                for message in batch:\n",
    "                    self._process_single_message(message)\n",
    "                \n",
    "                batch = []  # 清空批次\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"處理數據時發生錯誤：{e}\")\n",
    "                continue\n",
    "\n",
    "    def _process_single_message(self, message):\n",
    "        \"\"\"處理單條消息\"\"\"\n",
    "        try:\n",
    "            if message.startswith(\"data_5610:\"):\n",
    "                self._handle_data_5610(message)\n",
    "                self.logger.info(message)\n",
    "\n",
    "            elif message == \"ready to predict right leg\":\n",
    "                self.logger.info(\"ready to predict right leg\")\n",
    "                self.predict_state = 1\n",
    "                self.state = \"IDLE\"\n",
    "                self.start_prediction_thread()  # 啟動持續預測thread\n",
    "            elif message == \"ready to predict left leg\":\n",
    "                self.logger.info(\"ready to predict left leg\")\n",
    "                self.predict_state = 0\n",
    "                self.state = \"IDLE\"\n",
    "                self.prediction_active.clear()  # 停止預測\n",
    "\n",
    "            elif message == \"END\":\n",
    "                self._handle_end()\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.info(f\"處理消息時發生錯誤：{e}\")\n",
    "\n",
    "    def _handle_data_5610(self, message):\n",
    "        \"\"\"處理5610數據\"\"\"\n",
    "        start_time = time.time()  # 記錄開始時間\n",
    "        latest_data_5610 = message.replace(\"data_5610:\", \"\").strip()\n",
    "        latest_data_5610 = np.array(list(map(float, latest_data_5610.split(\",\")))).reshape(1, -1)\n",
    "        with tf.device('/GPU:0'):\n",
    "            latest_data_5610 = tf.convert_to_tensor(latest_data_5610, dtype=tf.float32) #\n",
    "        with self.data_lock:  # 只在寫入時鎖定\n",
    "            #self.data_5610 = np.vstack([self.data_5610 , latest_data_5610])\n",
    "            self.data_5610_tensor[self.data_index].assign(latest_data_5610[0])\n",
    "            # 更新索引，實現循環緩衝\n",
    "            self.data_index = (self.data_index + 1) % 10000\n",
    "            # 更新計數，最大為 10000\n",
    "            if self.data_count < 10000:\n",
    "                self.data_count += 1\n",
    "            self.logger.info(f\"Updated data_count: {self.data_count}\")  # 添加日誌\n",
    "    \n",
    "        #print(\"處理5610數據\")\n",
    "        end_time = time.time()  # 記錄結束時間\n",
    "        execution_time = end_time - start_time  # 計算執行時間\n",
    "        #print(f\"_handle_data_5610執行時間: {execution_time:.6f} 秒\")  # 輸出執行時間\n",
    "        self.logger.info(f\"_handle_data_5610執行時間: {execution_time:.6f} 秒\")\n",
    "\n",
    "    def start_prediction_thread(self):\n",
    "        \"\"\"啟動持續預測執行緒\"\"\"\n",
    "    # 如果已有執行中的預測執行緒，先停止它\n",
    "        if self.prediction_thread and self.prediction_thread.is_alive():\n",
    "            self.prediction_active.clear()\n",
    "            self.prediction_thread.join()\n",
    "        \n",
    "        # 重置並啟動新的預測執行緒\n",
    "        self.prediction_active.set()\n",
    "        self.prediction_thread = threading.Thread(target=self.prediction)\n",
    "        self.prediction_thread.start()\n",
    "\n",
    "    def prediction(self):\n",
    "        \"\"\"持續執行預測的執行緒函數\"\"\"\n",
    "        while self.prediction_active.is_set() and self.running_event.is_set():\n",
    "            try:\n",
    "                if self.predict_state == 1 and self.data_count > 40:\n",
    "                    self.logger.info(\"持續預測右腳\")\n",
    "                    result = self._handle_right_prediction()\n",
    "                    if not result:  # 若返回 False，退出\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                self.logger.info(f\"持續預測過程發生錯誤：{e}\")\n",
    "\n",
    "    #@numba.jit(nopython=True)  # 使用 Numba 編譯關鍵邏輯    \n",
    "    def _handle_right_prediction(self):\n",
    "        \"\"\"處理右腳預測\"\"\"\n",
    "        self.logger.info(\"處理右腳預測\")\n",
    "        if self.state == \"IDLE\":\n",
    "            try:\n",
    "                if self.state == \"IDLE\" and self.data_count > 40:\n",
    "                    start_time = time.time()\n",
    "                    self.start_index = self.data_index\n",
    "\n",
    "                    mid1 = time.time()\n",
    "                    self.logger.info(f\"1執行時間: {mid1 - start_time:.6f} 秒\")\n",
    "\n",
    "                    profiler_options = tf.profiler.experimental.ProfilerOptions(\n",
    "                        host_tracer_level=3,\n",
    "                        device_tracer_level=2,\n",
    "                        python_tracer_level=1\n",
    "                    )\n",
    "                    #tf.profiler.experimental.start('/mnt/c/Users/m2023/AppData/Local/Programs/Microsoft VS Code/logdir')\n",
    "                    with tf.device('/GPU:0'):\n",
    "                        future = combined_predict_and_detect(self.data_5610_tensor, self.data_count, self.data_index)\n",
    "                    #tf.profiler.experimental.stop()\n",
    "\n",
    "                    mid2 = time.time()\n",
    "                    self.logger.info(f\"Call time: {mid2 - mid1 :.6f} 秒\")  # 不含同步\n",
    "\n",
    "                    sync_start = time.time()\n",
    "                    signal = future.numpy()  # 顯式同步\n",
    "                    sync_end = time.time()\n",
    "                    self.logger.info(f\"Sync time: {sync_end - sync_start :.6f} 秒\")\n",
    "\n",
    "                    mid3 = time.time()\n",
    "                    self.logger.info(f\"3執行時間: {mid3 - mid1 :.6f} 秒\")\n",
    "\n",
    "                    self.logger.info(f\"signal右腳 {signal}\")\n",
    "                    end_time = time.time()\n",
    "                    execution_time = end_time - start_time\n",
    "                    self.logger.info(f\"_handle_right_prediction執行時間: {execution_time:.6f} 秒\")\n",
    "\n",
    "                if signal == 1:\n",
    "                    self.logger.info(\"右腳未來10步有 HeelStrike\")\n",
    "                    self.state = \"MONITOR_Right\"\n",
    "                \n",
    "                # if execution_time > 0.05:\n",
    "                #     self.logger.warning(\"預測時間超過0.045秒，可能跟不上數據速率\")\n",
    "                #     self.execution_overtime_count = getattr(self, 'execution_overtime_count', 0) + 1\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"{datetime.now()} 右腳預測發生錯誤：{e}\", exc_info=True)\n",
    "\n",
    "        elif self.state == \"MONITOR_Right\":\n",
    "            self.logger.info(\"開始右腳記步\")\n",
    "            self._monitor_right_steps()\n",
    "            if not self._monitor_right_steps():  # 檢查計步返回值\n",
    "                return False\n",
    "        \n",
    "        return True  # 繼續預測\n",
    "\n",
    "\n",
    "    def _monitor_right_steps(self):\n",
    "        \"\"\"監控右腳步數\"\"\"\n",
    "\n",
    "        last_printed_step = -1  # 記錄上一次打印的步數\n",
    "        while self.prediction_active.is_set() and self.running_event.is_set():\n",
    "            \n",
    "            #current_length = len(self.data_5610)\n",
    "            with self.data_lock:\n",
    "                current_index = self.data_index  # 獲取當前的 data_index\n",
    "            new_steps = (current_index - self.start_index) % 10000  # 使用 data_index 計算新步數\n",
    "            \n",
    "            if new_steps != last_printed_step:  # 僅在步數變化時打印\n",
    "                last_printed_step = new_steps\n",
    "                self.logger.info(f\"右腳步數第 {new_steps}\")\n",
    "                self.logger.info(f\"current_index: {current_index}, start_index: {self.start_index}, new_steps: {new_steps}\")\n",
    "            if new_steps == cue_step:\n",
    "                self.logger.info(\"亮右邊\")\n",
    "                #self._send_signal(\"0,1\")\n",
    "\n",
    "            if new_steps == 10:\n",
    "                with self.data_lock:  # 只在寫入結果時鎖定\n",
    "                    latest_index = (self.data_index - 1) % 10000\n",
    "                    predicted_time = self.data_5610_tensor[latest_index, 0]\n",
    "                    self.logger.info(f\"Writing predicted time {predicted_time} at index {latest_index}\")  # 调试日志\n",
    "                    self.R_HeelStrike_Predict_Time = np.vstack([\n",
    "                        self.R_HeelStrike_Predict_Time, \n",
    "                        self.data_5610_tensor[latest_index, 0]\n",
    "                    ])\n",
    "                self.logger.info(\"右腳10步\")\n",
    "                self.start_index = 0\n",
    "                self.state = \"IDLE\"\n",
    "                self.prediction_active.clear()  # 停止預測線程\n",
    "                return False  # 返回False表示要停止預測\n",
    "                \n",
    "            if new_steps > 10:            \n",
    "                self.start_index = 0\n",
    "                self.state = \"IDLE\"\n",
    "                self.prediction_active.clear()  # 停止預測線程\n",
    "                return False  # 返回False表示要停止預測\n",
    "            #time.sleep(0.005)\n",
    "\n",
    "#建立TCP For Unity,用於send\n",
    "    def TCP_For_Unity(self, host, port):\n",
    "        try:\n",
    "            # 定义Unity服务器的IP地址和端口号\n",
    "            unity_server_address = (host, port)  # 这里的IP地址和端口号应该与Unity服务器的设置相匹配\n",
    "\n",
    "            # 创建一个TCP/IP socket\n",
    "            client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "\n",
    "            # 连接到Unity服务器\n",
    "            client_socket.connect(unity_server_address)\n",
    "\n",
    "            # 发送信号到Unity服务器\n",
    "            def send_signal(signal):\n",
    "                message = signal.encode()  # 将信号转换为字节串\n",
    "                client_socket.sendall(message)  # 发送信号\n",
    "            return client_socket, send_signal\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"TCP For Unity發送錯誤：{e}\", exc_info=True)\n",
    "    \n",
    "#紀錄預測HS的真實時間\n",
    "    def save_data(self):\n",
    "        index_min=min(   len(self.R_HeelStrike_Predict_Time),  len(self.L_HeelStrike_Predict_Time)   )\n",
    "        index_0=np.array([[\"rightfoot\"]])\n",
    "        ee = np.vstack([index_0,self.R_HeelStrike_Predict_Time[1:index_min]])\n",
    "        index_0=np.array([[\"leftfoot\"]])\n",
    "        ff = np.vstack([index_0,self.L_HeelStrike_Predict_Time[1:index_min]])\n",
    "        gg = np.hstack([ee,ff])\n",
    "        gg_csv = pd.DataFrame(gg)\n",
    "        gg_csv.to_csv(output_file + TRIAL_NAME + 'predicthstime.csv',header=0,index=0)\n",
    "        self.logger.info(f\"預測結果已成功保存到 {output_file}\")\n",
    "\n",
    "\n",
    "    def _handle_end(self):\n",
    "        self.logger.info(\"結束信號接收，保存數據\")\n",
    "        self.prediction_active.clear()  # 停止預測執行緒\n",
    "        if self.prediction_thread:\n",
    "            self.prediction_thread.join()\n",
    "        self.save_data()\n",
    "        self.running_event.clear()  # 停止所有進程\n",
    "\n",
    "#建立TCP For IMU接收,用於receive\n",
    "    def TCP_For_IMU(self, host, port):\n",
    "        try:\n",
    "            server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            server.bind((host, port))\n",
    "            server.listen(1)  # 允許 1 個連線\n",
    "            self.logger.info(\"伺服器已啟動，等待連線...據\")\n",
    "\n",
    "            conn, addr = server.accept()\n",
    "            self.logger.info(f\"已連接來自 {addr} 的客戶端\")\n",
    "            return conn  # 回傳 conn 以供後續使用\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"TCP For IMU接收錯誤：{e}\", exc_info=True)   \n",
    "          \n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"啟動服務器\"\"\"\n",
    "        try:\n",
    "\n",
    "            dummy_data = tf.random.normal((10000, 7), dtype=tf.float32)\n",
    "            dummy_count = tf.constant(40, dtype=tf.int32)              # 假設有 40 筆資料\n",
    "            dummy_index = tf.constant(0, dtype=tf.int32)               # 索引從 0 開始\n",
    "            combined_predict_and_detect(dummy_data, dummy_count, dummy_index)\n",
    "            self.logger.info(\"模型已預熱\")\n",
    "\n",
    "            # 1. 初始化 Unity 客戶端\n",
    "            #client_socket, send_signal = self.TCP_For_Unity(host='localhost', port=12345)\n",
    "            # 2. 啟動 IMU 伺服器\n",
    "            conn = self.TCP_For_IMU(host='localhost', port=34567)\n",
    "            setup_logging()  # 在程式啟動時呼叫\n",
    "\n",
    "            \n",
    "            \n",
    "            # 創建並啟動線程\n",
    "            receiver_thread = threading.Thread(\n",
    "                target=self.receive_data, \n",
    "                args=(conn,)\n",
    "            )\n",
    "            processor_thread = threading.Thread(\n",
    "                target=self.process_data\n",
    "            )\n",
    "\n",
    "            receiver_thread.start()\n",
    "            processor_thread.start()\n",
    "\n",
    "\n",
    "            # 等待線程結束\n",
    "            receiver_thread.join()\n",
    "            processor_thread.join()\n",
    "\n",
    "            while self.running_event.is_set():\n",
    "                process = psutil.Process()\n",
    "                self.logger.info(f\"Memory usage: {process.memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "                time.sleep(10)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"服務器錯誤：{e}\", exc_info=True)\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"清理資源\"\"\"\n",
    "        self.running_event.clear()\n",
    "        if self.process_pool:\n",
    "            self.process_pool.shutdown()\n",
    "\n",
    "# 使用方式\n",
    "if __name__ == \"__main__\":\n",
    "    logger = setup_logging()\n",
    "    processor = DataProcessor(logger)\n",
    "    processor.start()  # 使用默認的 localhost:23456"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Predict_HS_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
